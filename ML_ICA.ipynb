{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# mne library\n",
    "import mne\n",
    "from mne import  read_epochs\n",
    "from mne.decoding import Vectorizer\n",
    "mne.set_log_level('error') # Avoid long log\n",
    "\n",
    "# Sklearn library\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the folder with the data\n",
    "path = 'files/prepocessed_ica'\n",
    "\n",
    "# Create a list with each tipe of experimental run\n",
    "openeye_runs = [1]\n",
    "closedeye_runs = [2]\n",
    "fists_runs = [3, 7, 11]\n",
    "imaginefists_runs = [4, 8, 12]\n",
    "fistsfeet_runs = [5, 9, 13]\n",
    "imaginefistsfeet_run = [6, 10, 14]\n",
    "\n",
    "# List of participants\n",
    "participants = [i for i in range(1,57)]\n",
    "\n",
    "\n",
    "# Here we charge the data, the idea is to keep the data of each subject together. \n",
    "# So we will create a list that contain a list for each subject, which containts all the epochs of the three experiences.\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for participant in participants:\n",
    "    participant_data = []\n",
    "    participant_labels = []\n",
    "    for run in fists_runs:\n",
    "        epochs = read_epochs(path + f'/S{participant:03}R{run:02}filt01_30_ICA_masref.fif')\n",
    "        participant_data.append(epochs.get_data())\n",
    "        participant_labels.append(epochs.events[:,-1])\n",
    "    data.append(np.concatenate(participant_data, axis = 0))\n",
    "    labels.append(np.concatenate(participant_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions:  (3571, 64, 817)\n",
      "y_train dimensions:  (3571,)\n",
      "X_test dimensions:  (947, 64, 817)\n",
      "y_test dimensions:  (947,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = np.concatenate(X_train, axis = 0)\n",
    "X_test = np.concatenate(X_test, axis = 0)\n",
    "y_train = np.concatenate(y_train, axis = 0)\n",
    "y_test = np.concatenate(y_test, axis = 0)\n",
    "\n",
    "print('X_train dimensions: ', X_train.shape)\n",
    "print('y_train dimensions: ', y_train.shape)\n",
    "print('X_test dimensions: ', X_test.shape)\n",
    "print('y_test dimensions: ', y_test.shape)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pip = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(random_state=42))\n",
    "parameters = {'logisticregression__penalty': ['l1', 'l2', 'elasticnet', None], 'logisticregression__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']}\n",
    "gs_lr_pip = GridSearchCV(lr_pip, parameters, scoring='accuracy', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=  12.9s\n",
      "[CV 2/5] END logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   3.3s\n",
      "[CV 3/5] END logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   2.8s\n",
      "[CV 4/5] END logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   2.8s\n",
      "[CV 5/5] END logisticregression__penalty=l1, logisticregression__solver=newton-cg;, score=nan total time=   2.8s\n",
      "[CV 1/5] END logisticregression__penalty=l1, logisticregression__solver=sag;, score=nan total time=   2.8s\n",
      "[CV 2/5] END logisticregression__penalty=l1, logisticregression__solver=sag;, score=nan total time=   2.8s\n",
      "[CV 3/5] END logisticregression__penalty=l1, logisticregression__solver=sag;, score=nan total time=   2.8s\n",
      "[CV 4/5] END logisticregression__penalty=l1, logisticregression__solver=sag;, score=nan total time=   2.8s\n",
      "[CV 5/5] END logisticregression__penalty=l1, logisticregression__solver=sag;, score=nan total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.635 total time=11.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.625 total time=11.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.613 total time=11.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.612 total time=11.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logisticregression__penalty=l1, logisticregression__solver=saga;, score=0.622 total time=11.1min\n",
      "[CV 1/5] END logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   3.6s\n",
      "[CV 2/5] END logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   2.7s\n",
      "[CV 3/5] END logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   2.7s\n",
      "[CV 4/5] END logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   2.7s\n",
      "[CV 5/5] END logisticregression__penalty=l1, logisticregression__solver=lbfgs;, score=nan total time=   2.6s\n",
      "[CV 1/5] END logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=0.620 total time= 3.8min\n",
      "[CV 2/5] END logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=0.552 total time= 3.8min\n",
      "[CV 3/5] END logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=0.580 total time= 5.2min\n",
      "[CV 4/5] END logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=0.627 total time= 4.7min\n",
      "[CV 5/5] END logisticregression__penalty=l2, logisticregression__solver=newton-cg;, score=0.602 total time= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logisticregression__penalty=l2, logisticregression__solver=sag;, score=0.614 total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logisticregression__penalty=l2, logisticregression__solver=sag;, score=0.623 total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logisticregression__penalty=l2, logisticregression__solver=sag;, score=0.612 total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logisticregression__penalty=l2, logisticregression__solver=sag;, score=0.615 total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logisticregression__penalty=l2, logisticregression__solver=sag;, score=0.622 total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.635 total time= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.618 total time= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.609 total time= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.616 total time= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logisticregression__penalty=l2, logisticregression__solver=saga;, score=0.613 total time= 5.8min\n",
      "[CV 1/5] END logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=0.608 total time= 1.1min\n",
      "[CV 2/5] END logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=0.574 total time=  58.1s\n",
      "[CV 3/5] END logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=0.590 total time= 1.0min\n",
      "[CV 4/5] END logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=0.595 total time= 1.2min\n",
      "[CV 5/5] END logisticregression__penalty=l2, logisticregression__solver=lbfgs;, score=0.602 total time=  58.4s\n",
      "[CV 1/5] END logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   3.1s\n",
      "[CV 2/5] END logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   3.1s\n",
      "[CV 3/5] END logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   3.1s\n",
      "[CV 4/5] END logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   3.1s\n",
      "[CV 5/5] END logisticregression__penalty=elasticnet, logisticregression__solver=newton-cg;, score=nan total time=   3.0s\n",
      "[CV 1/5] END logisticregression__penalty=elasticnet, logisticregression__solver=sag;, score=nan total time=   3.0s\n",
      "[CV 2/5] END logisticregression__penalty=elasticnet, logisticregression__solver=sag;, score=nan total time=   3.1s\n",
      "[CV 3/5] END logisticregression__penalty=elasticnet, logisticregression__solver=sag;, score=nan total time=   3.5s\n",
      "[CV 4/5] END logisticregression__penalty=elasticnet, logisticregression__solver=sag;, score=nan total time=   3.2s\n",
      "[CV 5/5] END logisticregression__penalty=elasticnet, logisticregression__solver=sag;, score=nan total time=   3.3s\n",
      "[CV 1/5] END logisticregression__penalty=elasticnet, logisticregression__solver=saga;, score=nan total time=   3.5s\n",
      "[CV 2/5] END logisticregression__penalty=elasticnet, logisticregression__solver=saga;, score=nan total time=   3.3s\n",
      "[CV 3/5] END logisticregression__penalty=elasticnet, logisticregression__solver=saga;, score=nan total time=   2.9s\n",
      "[CV 4/5] END logisticregression__penalty=elasticnet, logisticregression__solver=saga;, score=nan total time=   3.0s\n",
      "[CV 5/5] END logisticregression__penalty=elasticnet, logisticregression__solver=saga;, score=nan total time=   3.0s\n",
      "[CV 1/5] END logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   3.4s\n",
      "[CV 2/5] END logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   3.4s\n",
      "[CV 3/5] END logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   3.8s\n",
      "[CV 4/5] END logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   3.2s\n",
      "[CV 5/5] END logisticregression__penalty=elasticnet, logisticregression__solver=lbfgs;, score=nan total time=   3.5s\n",
      "[CV 1/5] END logisticregression__penalty=None, logisticregression__solver=newton-cg;, score=0.607 total time= 3.1min\n",
      "[CV 2/5] END logisticregression__penalty=None, logisticregression__solver=newton-cg;, score=0.556 total time= 2.5min\n",
      "[CV 3/5] END logisticregression__penalty=None, logisticregression__solver=newton-cg;, score=0.573 total time= 5.3min\n",
      "[CV 4/5] END logisticregression__penalty=None, logisticregression__solver=newton-cg;, score=0.612 total time= 2.5min\n",
      "[CV 5/5] END logisticregression__penalty=None, logisticregression__solver=newton-cg;, score=0.597 total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logisticregression__penalty=None, logisticregression__solver=sag;, score=0.614 total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logisticregression__penalty=None, logisticregression__solver=sag;, score=0.623 total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logisticregression__penalty=None, logisticregression__solver=sag;, score=0.612 total time= 4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logisticregression__penalty=None, logisticregression__solver=sag;, score=0.615 total time= 4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logisticregression__penalty=None, logisticregression__solver=sag;, score=0.622 total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logisticregression__penalty=None, logisticregression__solver=saga;, score=0.635 total time= 5.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logisticregression__penalty=None, logisticregression__solver=saga;, score=0.618 total time= 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logisticregression__penalty=None, logisticregression__solver=saga;, score=0.609 total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logisticregression__penalty=None, logisticregression__solver=saga;, score=0.616 total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logisticregression__penalty=None, logisticregression__solver=saga;, score=0.613 total time= 5.2min\n",
      "[CV 1/5] END logisticregression__penalty=None, logisticregression__solver=lbfgs;, score=0.597 total time=  45.6s\n",
      "[CV 2/5] END logisticregression__penalty=None, logisticregression__solver=lbfgs;, score=0.560 total time=  46.4s\n",
      "[CV 3/5] END logisticregression__penalty=None, logisticregression__solver=lbfgs;, score=0.580 total time=  45.9s\n",
      "[CV 4/5] END logisticregression__penalty=None, logisticregression__solver=lbfgs;, score=0.606 total time=  47.6s\n",
      "[CV 5/5] END logisticregression__penalty=None, logisticregression__solver=lbfgs;, score=0.598 total time=  42.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "35 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/elia/anaconda3/envs/mne/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.62139077        nan 0.59618499 0.61719496\n",
      " 0.61830953 0.59394723        nan        nan        nan        nan\n",
      " 0.5889056  0.61719496 0.61830953 0.58834812]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gs_lr_pip.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs_lr_pip.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6205450733752621\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_test == y_pred)/len(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
